{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a07442c6-9dd1-4d1b-9cb2-aadfd6616fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"\n",
    "    Di sebuah desa yang terkenal dengan hasil pertaniannya,\n",
    "    para petani menanam berbagai jenis buah seperti pisang, jeruk, dan apel.\n",
    "    Setiap musim panen tiba, apel menjadi buah yang paling banyak dicari karena rasanya\n",
    "    yang segar dan kandungan gizinya yang tinggi. Tidak hanya dijual dalam bentuk buah segar,\n",
    "    apel juga diolah menjadi jus, selai, dan kue oleh para pelaku UMKM setempat. Menariknya,\n",
    "    beberapa petani mulai bereksperimen dengan varietas apel baru yang lebih tahan terhadap perubahan cuaca.\n",
    "    Walaupun harga apel kadang naik turun di pasar, permintaan terhadap apel tetap stabil\n",
    "    karena masyarakat sudah terbiasa mengonsumsi Apeljack sebagai bagian dari gaya hidup sehat.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24e48dd9-9c0a-425a-9c31-52f06aa8e091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# count word \"Apel\" on paragraph using count \n",
    "# but when text include \"Apeljack\" it will still count\n",
    "\n",
    "wordApel = paragraph.lower().count(\"apel\")\n",
    "print(wordApel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e86db0e-69ab-4429-be22-2157818e9ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# count word \"Apel\" on pargraph using counter and regex\n",
    "import re\n",
    "\n",
    "wordApel = sum(1 for match in re.finditer(r\"\\bapel\\b\", paragraph.lower()))\n",
    "\n",
    "print(wordApel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b387076-8fe2-499a-a0c5-0fb6570dfa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# count word \"Apel\" on paragraph using counter and collections\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "wordApel = re.findall(r'\\b\\w+\\b', paragraph.lower())\n",
    "counter = Counter(wordApel)\n",
    "\n",
    "print(counter[\"apel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e00bdb4",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8de2e4-f5cb-4ac7-9172-a68efa2b9386",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "is a method for evaluating how important a word is in a documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "411cc05b-7a00-44ed-b8cc-3ef31f721464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/nlp/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/nlp/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "### install scikit-learn and pandas\n",
    "!pip install scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5487b49f-fba4-4307-a01e-ae159879e655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               apel  berwarna   dimakan       itu     merah     sudah  \\\n",
      "Dokumen A  0.449436  0.631667  0.000000  0.000000  0.631667  0.000000   \n",
      "Dokumen B  0.335176  0.000000  0.471078  0.471078  0.000000  0.471078   \n",
      "\n",
      "               ulat  \n",
      "Dokumen A  0.000000  \n",
      "Dokumen B  0.471078  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Setup data (korspus)\n",
    "# Dokumen A (Index 0) : \"Apel berwarna merah\"\n",
    "# Dokumen B (Index 1) : \"Apel itu sudah dimakan ulat\"\n",
    "\n",
    "corpus = [\n",
    "    \"Apel berwarna merah\",\n",
    "    \"Apel itu sudah dimakan ulat\"\n",
    "]\n",
    "\n",
    "# 2. Initialize Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# down here will start calculate using TF-IDF\n",
    "# 3. Calculate TF-IDF (Fit & Transform)\n",
    "# Machine will calculate (Fit) the value in docs\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# 4. Show result\n",
    "# get name \"word\" (feature) from machine\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# create table\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names, index=[\"Dokumen A\", \"Dokumen B\"])\n",
    "\n",
    "\n",
    "print(df_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e5fd25-0715-4af6-822a-58e6721d5754",
   "metadata": {},
   "source": [
    "Kata Apel itu mendapatakan nilai sekitar 0.4 dan 0.3 tidak terlalu tinggi nilainya (jika dilihat per dokumen) itu karna kata tersebut muncul di kedua dokumen, lalu ada kata bewarna merah di dok A sebagai \"ciri khas\" dokumen tersebut, sedangkan di dokumen B ada kata dimakan, itu, sudah sebagai ciri khas dokumen B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe0a70-ef92-4c0a-a1eb-cf65a85f9dae",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e576e77-29e9-4f4f-a874-992fb7b45f2b",
   "metadata": {},
   "source": [
    "Sebuah metode untuk mengukur seberapa mirip dua benda (dalam hal ini dokument/teks) dengan menghitung kosinus sudut di antara kedua vektor dokumen tersebut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "938fda44-f618-427c-bfaa-c864b8172c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7999999999999998\n"
     ]
    }
   ],
   "source": [
    "## implement\n",
    "# first using numpy\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# 1. vektor\n",
    "# Dokumen A: 1 Apel, 2 Manis\n",
    "\n",
    "vec_a = np.array([1,2])\n",
    "\n",
    "# Dokumen B: 2 Apel, 1 Manis\n",
    "\n",
    "vec_b = np.array([2,1])\n",
    "\n",
    "# 2. Calculate Dot Product\n",
    "# Rumus: (1*2) + (2*1) = 4\n",
    "\n",
    "dot_product = np.dot(vec_a, vec_b)\n",
    "\n",
    "# 3. Calculate (Magnitude / Length Vector)\n",
    "# Rumus: Akar ( ||A|| * ||B||)\n",
    "\n",
    "norm_a = norm(vec_a)\n",
    "norm_b = norm(vec_b)\n",
    "\n",
    "# 4. Hitung Cosine Similarity\n",
    "# Rumus: dot_product / (norm_a * norm_b)\n",
    "\n",
    "result = dot_product / (norm_a * norm_b)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fa95d1-43db-4008-be0b-1fae0930cf8e",
   "metadata": {},
   "source": [
    "Hasilnya 0.799... itu berarti dokumen A dan dokumen B memiliki kemiripan sekitar 79 - 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1bec30d-ff9f-49d9-aff2-0674fd113611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Cosine similarity : 0.7999999999999999\n"
     ]
    }
   ],
   "source": [
    "# Using scikit-learn\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data \n",
    "vec_a = np.array([[1,2]])\n",
    "vec_b = np.array([[2,1]])\n",
    "\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity = cosine_similarity(vec_a, vec_b)\n",
    "\n",
    "print(\"Hasil Cosine similarity :\", similarity[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1e2fa-cf32-431d-ae9d-a86cd28953dc",
   "metadata": {},
   "source": [
    "Hasilnya samaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4bb0e4-f1fe-4430-913f-96f8aa1ac3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5bf5581-1da2-4d11-aa83-be8eb6594a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/nlp/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/nlp/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/nlp/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b52ff494-7289-4bcd-9b43-b730457c9b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    algoritma      aman      anak  aplikasi      ayah   belajar  berangkat  \\\n",
      "0    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "1    0.000000  0.000000  0.000000  0.000000  0.416356  0.000000   0.000000   \n",
      "2    0.000000  0.000000  0.364711  0.000000  0.000000  0.411515   0.000000   \n",
      "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "4    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "5    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "6    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "7    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "8    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "9    0.000000  0.000000  0.000000  0.447214  0.000000  0.000000   0.000000   \n",
      "10   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "11   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "12   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "13   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "14   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "15   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "16   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "17   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "18   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "19   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "20   0.000000  0.000000  0.405852  0.000000  0.000000  0.000000   0.000000   \n",
      "21   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.420743   \n",
      "22   0.000000  0.457936  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "23   0.457128  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "24   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "\n",
      "     bergizi    berita  berkembang  ...     siang    sistem     tahun  \\\n",
      "0   0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "1   0.000000  0.416356    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "2   0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "3   0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "4   0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "5   0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "6   0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "7   0.000000  0.000000    0.408248  ...  0.000000  0.000000  0.408248   \n",
      "8   0.000000  0.000000    0.000000  ...  0.000000  0.457128  0.000000   \n",
      "9   0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "10  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "11  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "12  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "13  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "14  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "15  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "16  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "17  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "18  0.457128  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "19  0.000000  0.000000    0.000000  ...  0.441957  0.000000  0.000000   \n",
      "20  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "21  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "22  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "23  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "24  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
      "\n",
      "        tamu  teknologi    tempat     tetap     tubuh     tugas     untuk  \n",
      "0   0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "1   0.416356   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "2   0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3   0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "4   0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.424619  \n",
      "5   0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "6   0.000000   0.000000  0.000000  0.000000  0.000000  0.447214  0.000000  \n",
      "7   0.000000   0.408248  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "8   0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "9   0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "10  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "11  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "12  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "13  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "14  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "15  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "16  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "17  0.000000   0.000000  0.000000  0.408248  0.408248  0.000000  0.000000  \n",
      "18  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.405136  \n",
      "19  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "20  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "21  0.000000   0.000000  0.420743  0.000000  0.000000  0.000000  0.000000  \n",
      "22  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "23  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "24  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[25 rows x 120 columns]\n"
     ]
    }
   ],
   "source": [
    "## Exercise\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "list_data = [\n",
    "    \"Ibu memasak nasi di dapur rumah.\",\n",
    "    \"Ayah membaca berita pagi di ruang tamu.\",\n",
    "    \"Anak belajar menulis dan membaca di sekolah.\",\n",
    "    \"Guru menjelaskan pelajaran dengan sabar.\",\n",
    "    \"Komputer digunakan untuk mengolah data.\",\n",
    "    \"Internet membantu pencarian informasi dengan cepat.\",\n",
    "    \"Mahasiswa mengerjakan tugas menggunakan laptop.\",\n",
    "    \"Teknologi berkembang sangat pesat setiap tahun.\",\n",
    "    \"Sistem informasi mempermudah pekerjaan kantor.\",\n",
    "    \"Pengguna mengakses aplikasi melalui ponsel.\",\n",
    "    \"Cuaca hujan membuat jalanan menjadi licin.\",\n",
    "    \"Matahari bersinar cerah di pagi hari.\",\n",
    "    \"Kendaraan melaju pelan karena lalu lintas padat.\",\n",
    "    \"Perjalanan jauh membutuhkan persiapan matang.\",\n",
    "    \"Petani menanam padi di sawah.\",\n",
    "    \"Dokter memeriksa kesehatan pasien.\",\n",
    "    \"Rumah sakit menyediakan layanan medis.\",\n",
    "    \"Olahraga rutin menjaga tubuh tetap sehat.\",\n",
    "    \"Makanan bergizi penting untuk pertumbuhan.\",\n",
    "    \"Minuman dingin menyegarkan di siang hari.\",\n",
    "    \"Anak bermain bola di halaman rumah.\",\n",
    "    \"Pekerja berangkat pagi ke tempat kerja.\",\n",
    "    \"Data disimpan dengan aman di server.\",\n",
    "    \"Algoritma membantu proses pengambilan keputusan.\",s\n",
    "    \"Pembelajaran mesin digunakan dalam kecerdasan buatan.\"\n",
    "]\n",
    "tfidf_matrix = vectorizer.fit_transform(list_data)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "\n",
    "# implementasi cosine similarity\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
